{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13282549,"sourceType":"datasetVersion","datasetId":8417291}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Engineering and Extraction","metadata":{}},{"cell_type":"markdown","source":"### Imports and Setup","metadata":{}},{"cell_type":"code","source":"!pip install pymupdf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T13:29:30.220092Z","iopub.execute_input":"2025-10-17T13:29:30.220344Z","iopub.status.idle":"2025-10-17T13:29:36.255261Z","shell.execute_reply.started":"2025-10-17T13:29:30.220325Z","shell.execute_reply":"2025-10-17T13:29:36.253963Z"}},"outputs":[{"name":"stdout","text":"Collecting pymupdf\n  Downloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\nDownloading pymupdf-1.26.5-cp39-abi3-manylinux_2_28_x86_64.whl (24.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pymupdf\nSuccessfully installed pymupdf-1.26.5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import re\nimport fitz\nfrom pathlib import Path\nfrom PIL import Image\nimport io\n\n# for OCR of images\ntry:\n    import pytesseract\n    OCR_AVAILABLE = True\nexcept:\n    OCR_AVAILABLE = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-17T13:29:36.256402Z","iopub.execute_input":"2025-10-17T13:29:36.257100Z","iopub.status.idle":"2025-10-17T13:29:36.646992Z","shell.execute_reply.started":"2025-10-17T13:29:36.257056Z","shell.execute_reply":"2025-10-17T13:29:36.645999Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"### PDF Extractor and Cleaner","metadata":{}},{"cell_type":"code","source":"class PDFProcessor:\n    def __init__(self, pdf_paths, output_dir):\n        self.pdf_paths = pdf_paths\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(exist_ok=True)\n    \n    def run(self):\n        # Main pipeline execution\n        print(\"=\"*80)\n        print(\"PDF TO DATASET PIPELINE\")\n        print(\"=\"*80)\n        \n        # Extract\n        print(\"\\nExtracting from PDFs...\")\n        all_content = []\n        for pdf_path in self.pdf_paths:\n            print(f\"  - {Path(pdf_path).name}\")\n            content = self._extract_pdf(pdf_path)\n            all_content.append(content)\n        \n        # Clean\n        print(\"\\nCleaning and structuring...\")\n        combined = \"\\n\\n\" + \"=\"*80 + \"\\n\\n\".join(all_content)\n        final_text = self._clean(combined)\n        \n        # Save\n        output = self.output_dir / \"master_dataset.txt\"\n        output.write_text(final_text, encoding='utf-8')\n        \n        print(f\"\\n✓ Complete: {output}\")\n        print(f\"  Size: {len(final_text):,} chars\")\n        return final_text\n    \n    def _extract_pdf(self, path):\n        # Extract text and images from single file\n        doc = fitz.open(path)\n        pages = []\n        \n        for page_num, page in enumerate(doc):\n            text = page.get_text()\n            \n            # Process images\n            for img_idx, img_info in enumerate(page.get_images(full=True)):\n                try:\n                    xref = img_info[0]\n                    img_data = doc.extract_image(xref)\n                    img = Image.open(io.BytesIO(img_data[\"image\"]))\n                    \n                    # OCR if available\n                    ocr_text = \"\"\n                    if OCR_AVAILABLE and img:\n                        try:\n                            ocr_text = pytesseract.image_to_string(img).strip()\n                        except:\n                            pass\n                    \n                    # Create figure tag\n                    fig = f\"<figure>Page {page_num+1}, Image {img_idx+1}\"\n                    if ocr_text:\n                        fig += f\": {ocr_text[:150]}\"\n                    fig += \"</figure>\"\n                    text += f\"\\n\\n{fig}\\n\\n\"\n                except:\n                    pass\n            \n            pages.append(text)\n        \n        doc.close()\n        return \"\\n\\n\".join(pages)\n    \n    def _clean(self, text):\n        # Fix ligatures\n        for old, new in [('ﬁ','fi'), ('ﬂ','fl'), ('ﬀ','ff'), ('ﬃ','ffi'), ('ﬄ','ffl')]:\n            text = text.replace(old, new)\n        \n        # Fix encoding artifacts\n        for old, new in [('—','-'), ('–','-'), (''',\"'\"), (''',\"'\"), ('\"','\"'), ('\"','\"')]:\n            text = text.replace(old, new)\n        \n        # Fix broken code spacing\n        text = self._fix_code(text)\n        \n        # Remove PDF artifacts\n        lines = text.split('\\n')\n        keep = []\n        \n        # Patterns to skip\n        skip = [\n            r'^Sec\\.\\s+\\d+',                    # Sec. 1.1 Headers\n            r'^\\d+\\s+Chap\\.',                   # Chapter markers\n            r'^Chapter\\s+\\d+.+\\d+$',            # Chapter headers\n            r'^[ivxlcdm]+$',                    # Roman numerals\n            r'^\\d+$',                            # Page numbers\n            r'^Page\\s+\\d+',                      # Page markers\n            r'^SOURCE:',                         # Source tags\n            r'<metadata',                        # Metadata\n        ]\n        \n        for line in lines:\n            if not any(re.search(p, line.strip(), re.I) for p in skip):\n                keep.append(line)\n        \n        text = '\\n'.join(keep)\n        \n        # Fix hyphenation across lines\n        text = re.sub(r'(\\w+)-\\s*\\n\\s*(\\w+)', r'\\1\\2', text)\n        \n        # Normalize spaces\n        text = re.sub(r' {2,}', ' ', text)\n        text = re.sub(r'\\n{3,}', '\\n\\n', text)\n        \n        # Clean line endings\n        text = '\\n'.join(line.rstrip() for line in text.split('\\n'))\n        \n        return text.strip() + '\\n'\n    \n    def _fix_code(self, text):\n        # Fix code blocks with excessive spacing (r a n g e → range)\n        lines = text.split('\\n')\n        fixed = []\n        \n        for line in lines:\n            words = line.split()\n            \n            # if >60% are single chars, likely broken code\n            if len(words) > 5 and sum(len(w)==1 for w in words)/len(words) > 0.6:\n                # Remove spaces between single characters\n                line = re.sub(r'\\b([a-zA-Z0-9])\\s+(?=[a-zA-Z0-9]\\b)', r'\\1', line)\n                \n                # Fix common keywords\n                for broken, fixed_word in [\n                    (r'f\\s*o\\s*r\\b', 'for'),\n                    (r'i\\s*n\\b', 'in'),\n                    (r'i\\s*f\\b', 'if'),\n                    (r'd\\s*e\\s*f\\b', 'def'),\n                    (r'r\\s*a\\s*n\\s*g\\s*e', 'range'),\n                    (r'o\\s*r\\b', 'or'),\n                    (r'a\\s*n\\s*d\\b', 'and'),\n                    (r'n\\s*o\\s*t\\b', 'not'),\n                    (r'T\\s*r\\s*u\\s*e', 'True'),\n                    (r'F\\s*a\\s*l\\s*s\\s*e', 'False'),\n                ]:\n                    line = re.sub(broken, fixed_word, line)\n            \n            fixed.append(line)\n        \n        return '\\n'.join(fixed)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T13:29:36.648344Z","iopub.execute_input":"2025-10-17T13:29:36.648727Z","iopub.status.idle":"2025-10-17T13:29:36.662965Z","shell.execute_reply.started":"2025-10-17T13:29:36.648706Z","shell.execute_reply":"2025-10-17T13:29:36.661877Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### Main execution","metadata":{}},{"cell_type":"code","source":"books = [\"algo-li_yin\", \"computational_algos-jorg\", \"dsa_analysis-cliff\", \"ods-python\"]\nPDF_PATHS = [f\"/kaggle/input/dsa-books/{book}.pdf\" for book in books]\n\n# Run data extraction pipeline\npipeline = PDFProcessor(PDF_PATHS, output_dir=\"/kaggle/working\")\npipeline.run()\n\nprint(\"\\nReady for RAG!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-17T13:31:31.966907Z","iopub.execute_input":"2025-10-17T13:31:31.967162Z","iopub.status.idle":"2025-10-17T13:32:23.200686Z","shell.execute_reply.started":"2025-10-17T13:31:31.967139Z","shell.execute_reply":"2025-10-17T13:32:23.199781Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nPDF TO DATASET PIPELINE\n================================================================================\n\nExtracting from PDFs...\n  - algo-li_yin.pdf\n  - computational_algos-jorg.pdf\n  - dsa_analysis-cliff.pdf\n  - ods-python.pdf\n\nCleaning and structuring...\n\n✓ Complete: /kaggle/working/master_dataset.txt\n  Size: 4,753,030 chars\n\nReady for RAG!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}